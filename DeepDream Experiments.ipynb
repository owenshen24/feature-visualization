{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import psutil\n",
    "\n",
    "from utils import print_probs, transform, inverse_transform\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "# initialize net and set to evaluation mode\n",
    "net = models.resnet50(pretrained=True).to(device);\n",
    "net.eval()\n",
    "\n",
    "# Each layer in this list represents the first however many layers of resnet\n",
    "layers = [3,4,5,8] # For resnet50, layer can range from 0 to 9\n",
    "children = list(net.children())\n",
    "for i in range(len(layers)):\n",
    "    layers[i] = nn.Sequential(*children)[:layers[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "n_iterations = 20\n",
    "n_octaves = 4\n",
    "octave_scale = 1.4\n",
    "\n",
    "# set mean and std_deviation for imagenet\n",
    "mean = [.485, .456, .406]\n",
    "std = [.229, .224, .225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess image\n",
    "img = Image.open(\"images/rj-flower.jpg\")\n",
    "# img.show()\n",
    "img = transform(img).to(device)\n",
    "img = torch.unsqueeze(img, 0)\n",
    "\n",
    "#img = torch.rand(1, 3, 500, 500)\n",
    "\n",
    "# deep copy the image\n",
    "img_copy = img.clone().detach()\n",
    "\n",
    "# # normalize learning rate\n",
    "# learning_rate = learning_rate / (len(layers)*n_octaves)\n",
    "\n",
    "# Each octave_img is a zoomed-in (i.e. lower-res) version of the previous image\n",
    "# octave_imgs = [img[0].cpu().numpy()]\n",
    "# for i in range(n_octaves-1):\n",
    "#     new_octave_img = nd.zoom(octave_imgs[-1], (1, 1.0/octave_scale, 1.0/octave_scale),\n",
    "#                          order=2)\n",
    "#     octave_imgs.append(new_octave_img)\n",
    "# for i in range(len(octave_imgs)):\n",
    "#     octave_imgs[i] = torch.tensor(octave_imgs[i]).unsqueeze(0).float().to(device)\n",
    "# # Make the list low to high res\n",
    "# octave_imgs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "    for layer in layers:\n",
    "        # apply jitter\n",
    "        y_jitter, x_jitter = np.random.randint(-32, 32, size=2)\n",
    "        img = torch.roll(img, shifts=(y_jitter, x_jitter), dims=(-2, -1))\n",
    "        img = img.detach()\n",
    "        img.requires_grad = True\n",
    "        logits = layer(img)\n",
    "        #loss = -(logits**2).mean()\n",
    "        loss = -(logits[0]**2).mean()\n",
    "        loss.backward()\n",
    "        \n",
    "        g = img.grad.data\n",
    "        g = g/g.abs().mean()\n",
    "        img = img - learning_rate*g\n",
    "        \n",
    "        # Normalize image \n",
    "        # from https://github.com/eriklindernoren/PyTorch-Deep-Dream\n",
    "        for c in range(3):\n",
    "            m, s = mean[c], std[c]\n",
    "            img[0][c] = torch.clamp(img[0][c], -m/s, (1-m)/s)\n",
    "\n",
    "        # undo jitter\n",
    "        img = torch.roll(img, shifts=(-y_jitter, -x_jitter), dims=(-2, -1))\n",
    "\n",
    "# Display the difference between the two images\n",
    "diff = img_copy[0]-img[0].cpu()\n",
    "diff = inverse_transform(diff)\n",
    "diff.show()\n",
    "\n",
    "# Display dreamed image\n",
    "img = img[0].cpu()\n",
    "img = inverse_transform(img)\n",
    "img.show()\n",
    "img.save(\"temp.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python36764bitbasecondab7a8f070add3487eadfe15e733184a9b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

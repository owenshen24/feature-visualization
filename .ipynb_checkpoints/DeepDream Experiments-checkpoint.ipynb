{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import psutil\n",
    "\n",
    "from utils import print_probs, transform, inverse_transform\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "# initialize net and set to evaluation mode\n",
    "net = models.resnet50(pretrained=True).to(device);\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "n_iterations = 50\n",
    "# layers = [6,7,8,9] # For resnet50, layer can range from 0 to 9\n",
    "n_octaves = 4\n",
    "octave_scale = 1.4\n",
    "\n",
    "# set mean and std_deviation for imagenet\n",
    "mean = [.485, .456, .406]\n",
    "std = [.229, .224, .225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess image\n",
    "img = Image.open(\"mohit.jpg\")\n",
    "# img.show()\n",
    "img = transform(img).to(device)\n",
    "img = torch.unsqueeze(img, 0)\n",
    "\n",
    "# img = torch.rand(1, 3, 255, 255)\n",
    "\n",
    "# deep copy the image\n",
    "\n",
    "# # normalize learning rate\n",
    "# learning_rate = learning_rate / (len(layers)*n_octaves)\n",
    "\n",
    "# # Each layer in this list represents the first however many layers of resnet\n",
    "# children = list(net.children())\n",
    "# for i in range(len(layers)):\n",
    "#     layers[i] = nn.Sequential(*children)[:layers[i]-len(children)]\n",
    "\n",
    "# Each octave_img is a zoomed-in (i.e. lower-res) version of the previous image\n",
    "octave_imgs = [img[0].cpu().numpy()]\n",
    "for i in range(n_octaves-1):\n",
    "    new_octave_img = nd.zoom(octave_imgs[-1], (1, 1.0/octave_scale, 1.0/octave_scale),\n",
    "                         order=1)\n",
    "    octave_imgs.append(new_octave_img)\n",
    "for i in range(len(octave_imgs)):\n",
    "    octave_imgs[i] = torch.tensor(octave_imgs[i]).unsqueeze(0).float().to(device)\n",
    "# Make the list low to high res\n",
    "octave_imgs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for octave, octave_img in enumerate(octave_imgs):\n",
    "    im = img[0].cpu()\n",
    "    im = inverse_transform(im)\n",
    "    #im.show()\n",
    "    h, w = octave_img.shape[-2:]\n",
    "    if octave > 0:\n",
    "        # upscale previous octave's details\n",
    "        h1, w1 = detail.shape[-2:]\n",
    "        detail = detail[0].cpu().detach().numpy()\n",
    "        detail = nd.zoom(detail, (1, 1.0*h/h1, 1.0*w/w1), order=1)\n",
    "        detail = torch.tensor(detail).unsqueeze(0).float().to(device)\n",
    "        img = octave_img + detail\n",
    "    else:\n",
    "        img = octave_img\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        # apply jitter\n",
    "        layer = net\n",
    "        y_jitter, x_jitter = np.random.randint(-32, 32, size=2)\n",
    "        img = torch.roll(img, shifts=(y_jitter, x_jitter), dims=(-2, -1))\n",
    "        img = img.detach()\n",
    "\n",
    "        img.requires_grad = True\n",
    "        logits = layer(img)\n",
    "        loss = -(logits**2).mean()\n",
    "        #loss = -(logits[0]**2).mean()\n",
    "        loss.backward()\n",
    "\n",
    "        g = img.grad.data\n",
    "        g = g/g.abs().mean()\n",
    "        img = img - learning_rate*g\n",
    "\n",
    "        # Normalize image \n",
    "        # from https://github.com/eriklindernoren/PyTorch-Deep-Dream\n",
    "        for c in range(3):\n",
    "            m, s = mean[c], std[c]\n",
    "            img[0][c] = torch.clamp(img[0][c], -m/s, (1-m)/s)\n",
    "\n",
    "        # undo jitter\n",
    "        img = torch.roll(img, shifts=(-y_jitter, -x_jitter), dims=(-2, -1))\n",
    "        print(str(i) + ' ' + str(loss))\n",
    "    detail = img-octave_img\n",
    "\n",
    "# print(print_probs(F.softmax(net(img), dim=1)[0]))\n",
    "# print_probs(F.softmax(net(img)))\n",
    "\n",
    "img = img[0].cpu()\n",
    "img = inverse_transform(img)\n",
    "img.show()\n",
    "img.save(\"temp.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python36764bitbasecondab7a8f070add3487eadfe15e733184a9b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
